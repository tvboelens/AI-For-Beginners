{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to download the data and unpack the zip file. The dataset is very large, so downloading takes quite some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset, this might take a while\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-28 17:46:09--  https://www.di.ens.fr/willow/research/headdetection/release/HollywoodHeads.zip\n",
      "Herleiden van www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
      "Verbinding maken met www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... verbonden.\n",
      "HTTP-verzoek is verzonden; wachten op antwoord... 200 OK\n",
      "Lengte: niet-opgegeven [application/zip]\n",
      "Wordt opgeslagen als: ‘HollywoodHeads.zip’\n",
      "\n",
      "HollywoodHeads.zip      [  <=>               ]   5,36G  5,88MB/s    in 16m 15s \n",
      "\n",
      "2023-10-28 18:02:24 (5,63 MB/s) - '‘HollywoodHeads.zip’' opgeslagen [5755744131]\n",
      "\n",
      "Unzipping dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "\n",
    "if not os.path.exists('data'):#check if we have already unpacked the data\n",
    "    if not os.path.exists('HollywoodHeads.zip'):\n",
    "        print('Downloading dataset, this might take a while')\n",
    "        !wget https://www.di.ens.fr/willow/research/headdetection/release/HollywoodHeads.zip\n",
    "    with zipfile.ZipFile('HollywoodHeads.zip') as file:\n",
    "        print('Unzipping dataset')\n",
    "        file.extractall()\n",
    "        #!mv HollywoodHeads data\n",
    "    os.rename('HollywoodHeads','data')\n",
    "    !rm HollywoodHeads.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from xml.etree import ElementTree as et\n",
    "\n",
    "class HollywoodHeadDataset(Dataset):\n",
    "    def __init__(self, root, transforms=None, mode='train') -> None:\n",
    "        super().__init__()\n",
    "        self.transforms = transforms\n",
    "        self.root = root\n",
    "\n",
    "        filename = mode.lower() + '.txt'\n",
    "        filepath = os.path.join(root,'Splits',filename)\n",
    "\n",
    "        with open(filepath,'r') as f:\n",
    "            img_names = f.readlines()\n",
    "        self.imgs = [img.strip('\\n') for img in img_names]\n",
    "\n",
    "        self.imgs_dir = os.path.join(root, 'JPEGImages')\n",
    "        self.annot_dir = os.path.join(root, 'Annotations')\n",
    "        #self.classes = ['background','head']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.imgs[idx]+'.jpeg'\n",
    "        image_path = os.path.join(self.imgs_dir,img_filename)\n",
    "\n",
    "        annot_filename = self.imgs[idx]+'.xml'\n",
    "        annot_file_path = os.path.join(self.annot_dir,annot_filename)\n",
    "\n",
    "        img = torchvision.io.read_image(image_path, ImageReadMode.RGB)        \n",
    "        \n",
    "        boxes=[]\n",
    "        #labels=[]\n",
    "        tree = et.parse(annot_file_path)\n",
    "        root = tree.getroot()\n",
    "        for object in root.findall('object'):\n",
    "            labels.append(self.classes.index(object.find('name').text))\n",
    "            xmin=int(object.find('bndbox').find('xmin').text)\n",
    "            xmax=int(object.find('bndbox').find('xmin').text)\n",
    "\n",
    "            ymin=int(object.find('bndbox').find('ymin').text)\n",
    "            ymax=int(object.find('bndbox').find('ymax').text)\n",
    "\n",
    "            boxes.append([xmin,xmax,ymin,ymax])\n",
    "\n",
    "        area = (boxes[:,2]-boxes[:,1])*(boxes[:,4]-boxes[:,3])\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "\n",
    "        iscrowd = torch.zeros(boxes.shape[0],dtype=torch.int64)\n",
    "        \n",
    "        #We only have one class\n",
    "        labels=torch.ones(boxes.shape[0], dtype=torch.int64)\n",
    "\n",
    "        \n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
